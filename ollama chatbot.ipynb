{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous chat history loaded.\n",
      "Ollama: It looks like we got disconnected for a moment!\n",
      "\n",
      "Let's pick up where we left off. You were interested in using me as your LLM for an AI-powered space mission designer project. I provided some general requirements and ways I can contribute to the project.\n",
      "\n",
      "To move forward, what specific aspects of the project would you like to discuss or clarify? Would you like to provide more details about the project's scope, requirements, or desired outcomes?\n",
      "Ollama: Before we got disconnected, we were discussing your project for an AI-powered space mission designer. Specifically, I outlined the general requirements and ways I can contribute as your LLM, including:\n",
      "\n",
      "1. Domain knowledge encoding\n",
      "2. Argument generation\n",
      "3. Text-based interaction\n",
      "4. Knowledge graph construction\n",
      "\n",
      "We also started exploring how you'd like to use me in your project, but we didn't get a chance to dive deeper into the specifics.\n",
      "\n",
      "If you're ready to continue, what would you like to discuss next? Would you like to clarify any of these aspects or explore new topics related to your project?\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "chat_history_file = \"chat_history.txt\"\n",
    "\n",
    "def load_chat_history():\n",
    "    \"\"\"Load previous chat history from the file.\"\"\"\n",
    "    try:\n",
    "        with open(chat_history_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"\"\n",
    "\n",
    "def save_to_file(user_input, response):\n",
    "    \"\"\"Save the current interaction to the chat history file.\"\"\"\n",
    "    with open(chat_history_file, \"a\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"User: {user_input}\\n\")\n",
    "        file.write(f\"Ollama: {response}\\n\\n\")\n",
    "\n",
    "def chat_with_ollama():\n",
    "    \"\"\"Main function to interact with the model.\"\"\"\n",
    "    # Load existing chat history\n",
    "    chat_context = load_chat_history()\n",
    "    print(\"Previous chat history loaded.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"/bye\", \"exit\", \"quit\"]:\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            \n",
    "            # Combine chat history with the new user input\n",
    "            input_with_context = f\"{chat_context}\\nUser: {user_input}\"\n",
    "\n",
    "            # Run the command\n",
    "            process = subprocess.Popen(\n",
    "                [\"ollama\", \"run\", \"llama3.1:8b\"],\n",
    "                stdin=subprocess.PIPE,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True,\n",
    "                encoding=\"utf-8\",  # Ensure UTF-8 encoding\n",
    "                errors=\"replace\"   # Handle undecodable characters\n",
    "            )\n",
    "            response, _ = process.communicate(input=input_with_context)\n",
    "            response = response.strip()\n",
    "            print(f\"Ollama: {response}\")\n",
    "            \n",
    "            # Update the chat context and save the new interaction\n",
    "            chat_context += f\"\\nUser: {user_input}\\nOllama: {response}\\n\"\n",
    "            save_to_file(user_input, response)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_ollama()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
